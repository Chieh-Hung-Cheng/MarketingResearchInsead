library(lavaan)
library(semPlot)
library(psych)
library(readxl)
df = read.csv("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\interested.csv"); df
head(df)
summary(df)
hs <- df[,c(4:33)]; hs
head(hs)
hist(df$Q17_1)
# Specifying a CFA model
# To build a CFA model in lavaan, you??ll save a string with the model details.
# Each line is one latent factor, with its indicators following the =~ (read this symbol as ??is measured by??).
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_18 + Q17_22 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28 + Q17_29'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_18 + Q17_22 + Q17_23 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28 + Q17_29'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_18 + Q17_22 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28+ Q17_27 + Q17_29'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <-
' re  =~ Q17_1  + Q17_3 + Q17_7
sch =~Q17_10 + Q17_11
job = ~Q17_4+ Q17_8 + Q17_15 + Q17_22 + Q17_21 + Q17_24 + Q17_28 + Q17_29
abi =~Q17_16 + Q17_19
crr = ~Q17_12 + Q17_13 + Q17_14 + Q17_30
world = ~Q17_2 + Q17_5 + Q17_17 + Q17_18+ Q17_26'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_22 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28 + Q17_29'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_18 + Q17_22 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28 + Q17_29'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
HS.model <- ' cirr  =~ Q17_2  + Q17_5+ Q17_6 + Q17_12 + Q17_13 + Q17_14+ Q17_17 + Q17_18 + Q17_22 + Q17_30
job =~ Q17_9 + Q17_15 + Q17_11 + Q17_21 + Q17_24 + Q17_28 + Q17_29
res = ~Q17_4+Q17_8+Q17_10'
fit <- cfa(HS.model, data = df,
std.lv = TRUE)
summary(fit, fit.measures = TRUE, standardized = TRUE)
fitMeasures(fit, c("cfi","srmr","gfi","rmsea"))
#Alpha test
library(ltm)
resp = read.csv("C:\\Users\\ChiehHung\\Documents\\insead\\harvard_insead.csv"); resp
resp = read.csv("C:\\Users\\ChiehHung\\Documents\\insead\\havard_insead.csv"); resp
resp = read.csv("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\havard_insead.csv"); resp
cronbach.alpha(resp[,c(7,11,18)])
# Load the data
df = read.csvx("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\potentail.csv")
# Load the data
df = read.csvx("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\potential.csv")
# Load the data
df = read.csv("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\potential.csv")
head(df)
summary(df)
# Standardize the data
df_nmlz <- scale(df)
summary(df_nmlz)
head(df_nmlz)
head(df)
# Standardize the data
df_nmlz <- scale(df[:,3:])
# Standardize the data
df_nmlz <- scale(df[,3:])
# Standardize the data
df_nmlz <- scale(df[,3:28])
head(df_nmlz)
# Step 2.
# Compute the distance matrix
# df = the standardized data
res.dist <- dist(df_nmlz, method = "euclidean")
as.matrix(res.dist)[1:6, 1:6]
# Step 2.
# Compute the distance matrix
# df = the standardized data
res.dist <- dist(df_nmlz, method = "euclidean")
instpackages("factoextra")
install.packages("factoextra")
library("factoextra")
fviz_nbclust(df_nmlz,
FUNcluster = hcut,
method = "wss",
k.max = 10 )
# Step 2.
# Compute the distance matrix
# df = the standardized data
res.dist <- dist(df_nmlz, method = "euclidean")
as.matrix(res.dist)[1:389, 1:389]
res.hc <- hclust(d = res.dist, method = "ward.D2")
fviz_dend(res.hc, cex = 0.5)
cor(res.dist, res.coph)
res.coph <- cophenetic(res.hc)
cor(res.dist, res.coph)
fviz_nbclust(df_nmlz,
FUNcluster = hcut,
method = "wss",
k.max = 10 )
grp <- cutree(res.hc, k = 3)
grp <- cutree(res.hc, k = 3)
fviz_dend(res.hc, k = 4, rect = TRUE, cex = 0.5)
table(grp)
df = read.csv("C:\\Users\\ChiehHung\\PycharmProjects\\insead\\potential.csv")
head(df)
summary(df)
# Standardize
df_nmlz <- scale(df[,3:28])
head(df_nmlz)
summary(df_nmlz)
# Search # of clusters
fviz_nbclust(df_nmlz,
FUNcluster = hcut,
method = "wss",
k.max = 10 )
# Compute the distance matrix using normalized data
res.dist <- dist(df_nmlz, method = "euclidean")
as.matrix(res.dist)[1:389, 1:389]
# Clustering
res.hc <- hclust(d = res.dist, method = "ward.D2")
fviz_dend(res.hc, cex = 0.5)
res.coph <- cophenetic(res.hc)
cor(res.dist, res.coph)
# Cut and visualize
grp <- cutree(res.hc, k = 3)
fviz_dend(res.hc, k = 3, rect = TRUE, cex = 0.5)
table(grp)
rownames(df)[grp == 1]
grp == 1
df[grp == 1]
df[[grp == 1]]
grp
df[TRUE, TRUE]
df[grp==1,]
df[grp==1,]
df[grp==2,]
df[grp==3,]
